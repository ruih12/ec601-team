{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeSJ/d2lhWykm6VUKOWvwt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruih12/ec601-team/blob/main/preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Augmentation Implementation\n",
        "We can apply brightness, contrast, and noise adjustments as data augmentation techniques during the image preprocessing step. These modifications help enhance the modelâ€™s robustness, making it more adaptable to different lighting conditions and noise levels.\n",
        "\n",
        "Data Augmentation Implementation Code:"
      ],
      "metadata": {
        "id": "gq103C_4CsUP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXapjRQbCYEV"
      },
      "outputs": [],
      "source": [
        "# preprocess.py (Data Augmentation Part)\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def adjust_brightness_contrast(image, brightness=0, contrast=0):\n",
        "    # Adjust the brightness and contrast of an image\n",
        "    # brightness: [-100, 100] -> negative darkens, positive brightens\n",
        "    # contrast: [-100, 100] -> negative decreases contrast, positive increases\n",
        "    img = np.int16(image)\n",
        "    img = img * (contrast / 127 + 1) - contrast + brightness\n",
        "    img = np.clip(img, 0, 255)\n",
        "    return np.uint8(img)\n",
        "\n",
        "def add_noise(image, noise_level=0.02):\n",
        "    # Adds Gaussian noise to the image\n",
        "    # noise_level: controls noise intensity, larger values increase noise\n",
        "    noise = np.random.normal(0, 255 * noise_level, image.shape).astype(np.uint8)\n",
        "    noisy_image = cv2.add(image, noise)\n",
        "    return np.clip(noisy_image, 0, 255)\n",
        "\n",
        "def augment_image(image):\n",
        "    # Apply random data augmentation techniques\n",
        "    # Brightness and contrast adjustment\n",
        "    brightness = random.randint(-50, 50)\n",
        "    contrast = random.randint(-50, 50)\n",
        "    image = adjust_brightness_contrast(image, brightness, contrast)\n",
        "\n",
        "    # Add noise with a 50% chance\n",
        "    if random.random() < 0.5:\n",
        "        image = add_noise(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "def preprocess_images_with_augmentation(input_dir, output_dir):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for img_name in os.listdir(input_dir):\n",
        "        img_path = os.path.join(input_dir, img_name)\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            continue\n",
        "\n",
        "        # Apply data augmentation\n",
        "        image = augment_image(image)\n",
        "\n",
        "        # Save the augmented image\n",
        "        output_path = os.path.join(output_dir, img_name)\n",
        "        cv2.imwrite(output_path, image)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    input_directory = 'dataset/historical_figures/'\n",
        "    output_directory = 'dataset/augmented_figures/'\n",
        "    preprocess_images_with_augmentation(input_directory, output_directory)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "\n",
        "adjust_brightness_contrast: Adjusts pixel values to control brightness and contrast.\n",
        "\n",
        "add_noise: Adds Gaussian noise to simulate different image qualities.\n",
        "\n",
        "augment_image: Randomly applies brightness/contrast adjustments and noise addition.\n",
        "\n",
        "preprocess_images_with_augmentation: Processes the entire dataset and saves the augmented images."
      ],
      "metadata": {
        "id": "XmpGChvgCwqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Face Mask Implementation\n",
        "A face mask can be used to better align facial features and avoid focusing on the background. Here, we use Dlib to extract facial landmarks and create a mask over the face region, effectively masking out the non-facial background.\n",
        "\n",
        "Face Mask Implementation Code:"
      ],
      "metadata": {
        "id": "3t1pI3ZuC0GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess.py (Face Mask Part)\n",
        "\n",
        "import dlib\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Initialize face detector and facial landmark predictor\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "def create_face_mask(image, landmarks):\n",
        "    # Create a face mask based on facial landmarks\n",
        "    mask = np.zeros_like(image, dtype=np.uint8)\n",
        "\n",
        "    # Define face contour region\n",
        "    points = []\n",
        "    for i in range(0, 17):  # Jawline\n",
        "        points.append((landmarks.part(i).x, landmarks.part(i).y))\n",
        "    for i in range(26, 16, -1):  # Connect the top of the eyebrows to the jawline\n",
        "        points.append((landmarks.part(i).x, landmarks.part(i).y))\n",
        "\n",
        "    points = np.array(points, dtype=np.int32)\n",
        "\n",
        "    # Fill the contour area to form the mask\n",
        "    cv2.fillPoly(mask, [points], (255, 255, 255))\n",
        "\n",
        "    # Apply mask to the image\n",
        "    face_only_image = cv2.bitwise_and(image, mask)\n",
        "    return face_only_image\n",
        "\n",
        "def preprocess_images_with_mask(input_dir, output_dir):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for img_name in os.listdir(input_dir):\n",
        "        img_path = os.path.join(input_dir, img_name)\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            continue\n",
        "\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        faces = detector(gray)\n",
        "\n",
        "        for face in faces:\n",
        "            # Detect facial landmarks\n",
        "            landmarks = predictor(gray, face)\n",
        "            masked_image = create_face_mask(image, landmarks)\n",
        "\n",
        "            # Save the masked image\n",
        "            output_path = os.path.join(output_dir, img_name)\n",
        "            cv2.imwrite(output_path, masked_image)\n",
        "            break  # Only process the first detected face\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    input_directory = 'dataset/historical_figures/'\n",
        "    output_directory = 'dataset/masked_figures/'\n",
        "    preprocess_images_with_mask(input_directory, output_directory)\n"
      ],
      "metadata": {
        "id": "K8Rx2bJ4C3Ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "\n",
        "create_face_mask: Generates a face contour mask using landmarks. The mask is created by filling a polygon covering the face region, effectively excluding the background.\n",
        "\n",
        "preprocess_images_with_mask: Applies the face mask to each image in the dataset and saves the result."
      ],
      "metadata": {
        "id": "lLFDFOGmC7v6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining Data Augmentation and Face Mask\n",
        "We can integrate both data augmentation and face masking into a single preprocessing workflow to further improve image quality and alignment.\n",
        "\n",
        "Combined Code Example:"
      ],
      "metadata": {
        "id": "ZGjYmhPNC9Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images_with_augmentation_and_mask(input_dir, output_dir):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for img_name in os.listdir(input_dir):\n",
        "        img_path = os.path.join(input_dir, img_name)\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            continue\n",
        "\n",
        "        # Apply data augmentation\n",
        "        image = augment_image(image)\n",
        "\n",
        "        # Convert to grayscale and detect face\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        faces = detector(gray)\n",
        "\n",
        "        for face in faces:\n",
        "            landmarks = predictor(gray, face)\n",
        "            # Apply face mask\n",
        "            masked_image = create_face_mask(image, landmarks)\n",
        "\n",
        "            # Save the processed image\n",
        "            output_path = os.path.join(output_dir, img_name)\n",
        "            cv2.imwrite(output_path, masked_image)\n",
        "            break  # Only process the first detected face\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    input_directory = 'dataset/historical_figures/'\n",
        "    output_directory = 'dataset/augmented_masked_figures/'\n",
        "    preprocess_images_with_augmentation_and_mask(input_directory, output_directory)\n"
      ],
      "metadata": {
        "id": "9WxkDK0TC_3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combined Workflow:\n",
        "\n",
        "Data Augmentation: First, the image undergoes brightness/contrast adjustments and noise augmentation to improve robustness under different lighting and noise conditions.\n",
        "\n",
        "Face Masking: A face mask is applied to the augmented image to isolate the face and exclude any distracting background elements.\n",
        "\n",
        "Save Processed Image: The final processed image is saved to the specified directory."
      ],
      "metadata": {
        "id": "DGI7lzH5DB4e"
      }
    }
  ]
}